<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Explain K-nearest neighbor algorithm in detail - Machine Learning Notes</title>
  <link rel="stylesheet" href="static/style.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" />
  <meta name="description" content="Machine Learning Notes - Comprehensive study material" />
  <meta name="theme-color" content="#0f1724" />
</head>
<body>
  <header class="site-header">
    <div class="wrap">
      <div class="header-content">
        <h1><a href="index.html"><i class="fas fa-brain"></i> ML Notes</a></h1>
        <button class="bookmark-toggle" id="bookmarkToggle" title="View Bookmarks">
          <i class="fas fa-bookmark"></i>
          <span class="bookmark-count" id="bookmarkCount">0</span>
        </button>
      </div>
    </div>
  </header>
  
  <div class="bookmark-panel" id="bookmarkPanel">
    <div class="bookmark-panel-header">
      <h2><i class="fas fa-bookmark"></i> Bookmarks</h2>
      <button class="close-panel" id="closePanel"><i class="fas fa-times"></i></button>
    </div>
    <div class="bookmark-list" id="bookmarkList">
      <p class="empty-bookmarks">No bookmarks yet. Click the bookmark icon on any question to save it.</p>
    </div>
  </div>
  
  <main class="wrap content">
    <a href="index.html" class="back-btn"><i class="fas fa-arrow-left"></i> Back to Questions</a><h2 id="k-nearest-neighbor-knn-algorithm">K-Nearest Neighbor (KNN) Algorithm –</h2>
<p>Definition:
K-Nearest Neighbor (KNN) is a supervised machine learning algorithm used for both classification and regression problems.
It predicts the output for a new data point by looking at the ‘K’ nearest data points in the training dataset and choosing the most common class (for classification) or average value (for regression).</p>
<hr>
<p>Working of KNN Algorithm:</p>
<ol>
<li>Choose the number of neighbors (K):</li>
</ol>
<p>Select a suitable value of K (e.g., 3, 5, 7).</p>
<p>K decides how many nearby points will be considered when making a prediction.</p>
<ol>
<li>Calculate the distance:</li>
</ol>
<p>Find the distance between the new data point and all other data points in the training set.</p>
<p>Common distance formulas used are:</p>
<p>Euclidean Distance</p>
<p>d = √((x₂ - x₁)² + (y₂ - y₁)²)</p>
<ol>
<li>Find the nearest neighbors:</li>
</ol>
<p>Sort all distances and select the K smallest distances (the closest points).</p>
<ol>
<li>Voting or Averaging:</li>
</ol>
<p>For classification: Choose the class that appears most among the K neighbors.</p>
<p>For regression: Take the average of the K nearest values.</p>
<ol>
<li>Predict the result:</li>
</ol>
<p>The selected class or averaged value becomes the model’s prediction.</p>
<hr>
<p>Example:</p>
<p>Suppose we want to classify whether a fruit is an apple or orange based on its weight and color.
If K = 3, and among the 3 nearest neighbors,</p>
<p>2 are apples and 1 is orange → the new fruit is predicted as apple.</p>
<hr>
<p>Advantages:</p>
<p>Simple and easy to implement.</p>
<p>No training phase required (lazy learner).</p>
<p>Works well with small datasets.</p>
<hr>
<p>Disadvantages:</p>
<p>Slow for large datasets because it compares every point.</p>
<p>Sensitive to noisy data and irrelevant features.</p>
<p>Requires normalization of data for accurate distance calculation.</p>
<hr>
<p>✅ In short:
KNN is a lazy learning algorithm that classifies or predicts based on similarity (distance) between data points.
It’s simple and effective for small datasets but less efficient for large or high-dimensional data.</p><button class="page-bookmark-btn" id="pageBookmarkBtn" data-slug="Q6.html" data-title="Explain K-nearest neighbor algorithm in detail" title="Bookmark this question"><i class="far fa-bookmark"></i></button>
  </main>
  
  <footer class="wrap site-footer">
    <p>Machine Learning Notes • Study Material</p>
  </footer>
  
  <script src="static/script.js"></script>
</body>
</html>
