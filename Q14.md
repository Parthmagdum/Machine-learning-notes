# Bias and Variance in Machine Learning (4 Marks)

Definition:
Bias and Variance are two types of errors in Machine Learning that affect a model’s accuracy and performance.
They are part of the Bias-Variance Tradeoff, which helps in finding the right balance between underfitting and overfitting.


---

1. Bias:

Bias means the error due to wrong assumptions made by the model.

A high bias model is too simple and ignores important data patterns.

It leads to underfitting — the model performs poorly on both training and testing data.


Example:

Using a straight line (Linear Regression) to fit data that actually forms a curve.



---

2. Variance:

Variance means the error due to too much sensitivity to small changes in the training data.

A high variance model learns noise and unnecessary details.

It leads to overfitting — the model performs well on training data but poorly on testing data.


Example:

A complex decision tree that fits every data point perfectly but fails on new data.



---

✅ In short:

High Bias → Underfitting → Model too simple.

High Variance → Overfitting → Model too complex.
A good ML model keeps a balance between bias and variance for best accuracy.